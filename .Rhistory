library(tidyverse) ## for efficient cleaning of data frames
library(wru) ## for predicting race of profs
library(foreign) ## for reading in of csv files and such
library(rstudioapi) ## for efficient grabbing of working directory info
library(ggplot2) ## for cool plots
library(irr)
library(arm)
library(peRspective)
library(peRspective)
## rename col
colnames(osu_faculty_demos_miss)[3] <- "surname"
library(peRspective)
.libPaths()
##
library("remotes")
install_github("cran/peRspective")
library(peRspective)
library(grid)
library(stargazer)
###setting directory
main_wd <- dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(main_wd)
### import faculty characteristics data
osu_faculty_demos <- read.csv("OSU_faculty_demos.csv")
unc_faculty_demos <- read.csv("UNC_faculty_demos.csv")
### analyze race missings
table(osu_faculty_demos$non_white) ## 42 missing
table(unc_faculty_demos$non_white) ## none missing
### subset osu
osu_faculty_demos_miss <- subset(osu_faculty_demos, non_white==99)
osu_faculty_demos <- subset(osu_faculty_demos, non_white!=99)
## rename col
colnames(osu_faculty_demos_miss)[3] <- "surname"
colnames(osu_faculty_demos_miss)[2] <- "first"
osu_faculty_demos_miss <-  predict_race(osu_faculty_demos_miss, surname.only = T,
names.to.use = "surname, first" )
### we are just going with white and non white, so can use basic thresholds
osu_faculty_demos_miss$non_white[osu_faculty_demos_miss$pred.whi>0.5] <- 0
osu_faculty_demos_miss$non_white[osu_faculty_demos_miss$pred.whi<0.5] <- 1
### now, rename
colnames(osu_faculty_demos_miss)[2] <- "prof_firstname"
colnames(osu_faculty_demos_miss)[3] <- "prof_lastname"
## now, drop the wru stuff
osu_faculty_demos_miss <- osu_faculty_demos_miss[,1:8]
## rebind
osu_faculty_demos <- rbind(osu_faculty_demos, osu_faculty_demos_miss)
### api key
pr_api <- "AIzaSyBcW836khRPsqS-Fkkm7P0LNfk4B98_sZ0"
## read in the final data
gabe_coms <- read.csv(local_files[grepl("gabe", local_files) & grepl("final", local_files)])
###calculation of the OSU inter reliability
### Read in the csv data
local_files <-list.files(full.names=T)
local_files <- local_files[grepl(".csv",local_files)] ## subset to only include csv files
## read in the final data
gabe_coms <- read.csv(local_files[grepl("gabe", local_files) & grepl("final", local_files)])
koen_coms <- read.csv(local_files[grepl("koen", local_files) & grepl("final", local_files)])
### since dealing with the final data, should be good to go.
dim(gabe_coms) ## 33 cols, 2800 rows
sum(is.na(gabe_coms$out_emo_lang)==T) # no missing
sum(is.na(koen_coms$out_emo_lang)==T) # no missing
### lets create an aggregate index of the dims of interest
koen_coms$outrage_agg <- rowSums(koen_coms[,grepl("out_", colnames(koen_coms))])
koen_coms$personal_attack_agg <- rowSums(koen_coms[,grepl("pa_", colnames(koen_coms))])
koen_coms$prejudice_agg <- rowSums(koen_coms[,grepl("pb_", colnames(koen_coms))])
### now same for Gabe
gabe_coms$outrage_agg <- rowSums(gabe_coms[,grepl("out_", colnames(gabe_coms))])
gabe_coms$personal_attack_agg <- rowSums(gabe_coms[,grepl("pa_", colnames(gabe_coms))])
gabe_coms$prejudice_agg <- rowSums(gabe_coms[,grepl("pb_", colnames(gabe_coms))])
## get rid of thumbs data
gabe_coms <- subset(gabe_coms, select=-c(thumbs_up,thumbs_down))
koen_coms <- subset(koen_coms, select=-c(thumbs_up,thumbs_down))
## let's get total toxicity
gabe_coms$total_toxic <- gabe_coms$outrage_agg + gabe_coms$personal_attack_agg + gabe_coms$prejudice_agg
koen_coms$total_toxic <- koen_coms$outrage_agg + koen_coms$personal_attack_agg + koen_coms$prejudice_agg
### now let's get the score
## bind into matrix
test_mat_osu <- matrix(cbind(koen_coms$total_toxic,gabe_coms$total_toxic),ncol=2)
## ICC here
toxic_icc_osu <- icc(test_mat_osu, "oneway", "agreement")
## split for 1100
test_mat_osu1100 <- test_mat_osu[1:1100,]
toxic_icc_osu1100 <- icc(test_mat_osu1100, "oneway", "agreement")
# .658 for these, 95% of .623 to .69
test_mat_osu1100other <- test_mat_osu[1101:2800,]
toxic_icc_osu1100oth <- icc(test_mat_osu1100other, "oneway", "agreement")
### now, get the total difference between these
test_mat_osu_df <- as.data.frame(test_mat_osu)
test_mat_osu_df$abs_diff <- abs(test_mat_osu_df$V1-test_mat_osu_df$V2)
table(test_mat_osu_df$abs_diff[1:1100])
length(which(test_mat_osu_df$abs_diff[1:1100] > 0))
local_files[grepl("gabe", local_files) & grepl("final", local_files)]
local_files[grepl("koen", local_files) & grepl("final", local_files)]
head(rmp_df_osu)
### read in the full OSU data
rmp_df_osu <- read.csv("text_cleaning_data/scored_rmp_data_osu_final.csv") # this is the combination
head(rmp_df_osu)
# of the work by Koen and Gabe. We will need to ensure that we also get at the index level checks
### create ID field
rmp_df_osu$row_id <- seq.int(nrow(rmp_df_osu))
### good, now let's run the peRspective stuff
models2run <- c("TOXICITY","SEVERE_TOXICITY","INSULT")
### run here
persp_rmp_output_osu <- rmp_df_osu %>%
prsp_stream(text = comment,
text_id = row_id,
score_model = models2run)
### api key
pr_api <- "AIzaSyBcW836khRPsqS-Fkkm7P0LNfk4B98_sZ0"
### run here
persp_rmp_output_osu <- rmp_df_osu %>%
prsp_stream(text = comment,
text_id = row_id,
score_model = models2run)
prsp_stream
?prsp_stream
# check if api key present
perspective_api_key(test = F)
Sys.setenv(perspective_api_key = pr_api)
perspective_api_key(test = F)
Sys.setenv(perspective_api_key = pr_api)
### run here
persp_rmp_output_osu <- rmp_df_osu %>%
prsp_stream(text = comment,
text_id = row_id,
score_model = models2run)
### save the data
saveRDS(persp_rmp_output_osu, "persp_rmp_output_osu.rds")
persp_rmp_output_osu <- readRDS("persp_rmp_output_osu.rds")
### now merge with the data
rmp_df_osu2 <- merge(rmp_df_osu,persp_rmp_output_osu,by.x="row_id",by.y="text_id" )
rmp_df_osu2$total_toxicity =
(rmp_df_osu2$outrage_agg+rmp_df_osu2$prejudice_agg+rmp_df_osu2$personal_attack_agg)/2
quantile(rmp_df_osu2$total_toxicity,seq(0,1,by=0.05)) # so about 10% have one element; max is 5
### let's check how many are not 0
length(which(rmp_df_osu2$total_toxicity>0))
rmp_df_osu2$TOXICITY2 <- rmp_df_osu2$TOXICITY+rmp_df_osu2$SEVERE_TOXICITY
rmp_df_osu2toxic <- subset(rmp_df_osu2, total_toxicity >0 )
rmp_df_osu2nontoxic <- subset(rmp_df_osu2, total_toxicity ==0 )
quantile(rmp_df_osu2nontoxic$TOXICITY2,seq(0,1,by=0.05)) # for non-tox, 0.1 is just below 90th
quantile(rmp_df_osu2toxic$TOXICITY2,seq(0,1,by=0.05)) ### for the toxic labels, 0.1 is about 35th pct
### quick test of range
test_sub <- subset(rmp_df_osu2toxic,TOXICITY2 <= 0.10 )
quantile(test_sub$total_toxicity, seq(0,1,by=0.05)) # so within these data, the limit is 3
table(test_sub$total_toxicity)
table(rmp_df_osu2toxic$total_toxicity) # so in this regard, total of 20 data at 3, and of these,
# 90% still in the data. For 2-2.5, 13 excluded, 84 present. Therefore, 86 percent retained. OVerall, not
# too bad. IF we are able to keep a false pos rate of 10 percent, it shouldn't be too bad
### now randomly sample
set.seed(1337)
rmp_df_osu2nontoxic_sub<-sample_n(rmp_df_osu2nontoxic, nrow(rmp_df_osu2toxic))
### now bind the data
test_set_osu_rmp <- rbind(rmp_df_osu2toxic,rmp_df_osu2nontoxic)
###save here
saveRDS(test_set_osu_rmp, "test_set_osu_rmp.rds")
test_set_osu_rmp <- readRDS("test_set_osu_rmp.rds")
names(test_set_osu_rmp)
test_set_osu_rmp$coded_toxic = 0
test_set_osu_rmp$coded_toxic[test_set_osu_rmp$total_toxicity>0] = 1
###export the data here
write.csv(test_set_osu_rmp,"final_data/labeled_osu_data.csv",row.names = F)
test_set_osu_rmp <- readRDS("test_set_osu_rmp.rds")
names(test_set_osu_rmp)
test_set_osu_rmp$coded_toxic = 0
test_set_osu_rmp$coded_toxic[test_set_osu_rmp$total_toxicity>0] = 1
###export the data here
write.csv(test_set_osu_rmp,"final_data/labeled_osu_data.csv",row.names = F)
5000 + 500  + 230
5750/250
5750*.001
6000/250
6000/5750
